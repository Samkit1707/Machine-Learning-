{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aindri11/Machine-Learning-Lab/blob/main/Object_Detection_using_Yolo_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00YwC4iGGVdx"
      },
      "source": [
        "\n",
        "\\# **Using Yolo v7 for object detection in images and videos**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "4YXuqjQt8JYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ar0TPTzgwd",
        "outputId": "bedb64ec-ee1b-4d5d-9535-081b9d863ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z33plEjeNuw-",
        "outputId": "9ee29b5c-bfea-4bd5-9d1b-487ccbdb97dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CarIMTuS9RJ"
      },
      "source": [
        "Create Directories and Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQoFmcsqOg8Y",
        "outputId": "b44f2375-6453-4048-b6a3-9cbff71cc5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zmkD3wXOqtY"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(\"Mydir\"):\n",
        "  os.makedirs(\"Mydir\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUuXWy6oSkgG",
        "outputId": "69a603af-ba91-4613-f1e8-b2104b795531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mydir\n"
          ]
        }
      ],
      "source": [
        "%cd Mydir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Wp1tDUSoye",
        "outputId": "0ba87f8c-3f00-4dcb-ddbe-401e12f31fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mydir\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMgdNOUZSp-d",
        "outputId": "5fb93cdb-68c7-4d30-d352-7d88d1d30349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov7' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnVl1t1JTJjr"
      },
      "source": [
        "Download Pre Trained Model YOLO v7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We0eBUhoTJCh",
        "outputId": "8f7cf92b-bf75-4cd8-ab6c-7405406b8046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mydir/yolov7\n"
          ]
        }
      ],
      "source": [
        "%cd yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdCP7GPPS2fx",
        "outputId": "edfdd377-81a2-4b4d-d7ce-261268354af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-09 03:10:22--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240509%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240509T031022Z&X-Amz-Expires=300&X-Amz-Signature=8ca0d9688b46557edb623f6a47c94da89769b8c71a25150569fa4d5cd3db4a10&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-09 03:10:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240509%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240509T031022Z&X-Amz-Expires=300&X-Amz-Signature=8ca0d9688b46557edb623f6a47c94da89769b8c71a25150569fa4d5cd3db4a10&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7.pt.2’\n",
            "\n",
            "yolov7.pt.2         100%[===================>]  72.08M  38.2MB/s    in 1.9s    \n",
            "\n",
            "2024-05-09 03:10:24 (38.2 MB/s) - ‘yolov7.pt.2’ saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtpoCDtJU_N5",
        "outputId": "6a814df2-51bd-4b52-c4b1-1edcbc3545a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mydir/yolov7\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs-8ihFze81e",
        "outputId": "b5c5f660-96b1-4b46-c8b6-d449211365e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['yolov7.pt'], source='image1.jpg', img_size=640, conf_thres=0.5, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1 dog, Done. (1715.1ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp10/image1.jpg\n",
            "Done. (3.340s)\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights yolov7.pt --conf 0.5 --img-size 640 --source image1.jpg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov7.pt --conf 0.5 --img-size 640 --source img2.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJWppUmCTwcg",
        "outputId": "edef3a78-e69f-4afd-d84b-3c3d554dddaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['yolov7.pt'], source='img2.jpg', img_size=640, conf_thres=0.5, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1 person, 1 skateboard, Done. (2774.9ms) Inference, (2.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp11/img2.jpg\n",
            "Done. (3.501s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov7.pt --conf 0.5 --img-size 640 --source img3.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CroN1bb4TwKf",
        "outputId": "0f9e7375-bf4b-496f-eec8-2a4aba3a5ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['yolov7.pt'], source='img3.jpg', img_size=640, conf_thres=0.5, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1 cat, 1 potted plant, Done. (1861.7ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp12/img3.jpg\n",
            "Done. (2.892s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov7.pt --conf 0.5 --img-size 640 --source img4.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTqUnmspT4L_",
        "outputId": "9446105e-c0c0-4912-8dfc-7d4038daa7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['yolov7.pt'], source='img4.jpg', img_size=640, conf_thres=0.5, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "Done. (2604.1ms) Inference, (0.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp13/img4.jpg\n",
            "Done. (4.046s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1g2nYSdM1Uj",
        "outputId": "a34b6a83-6d79-4d33-b84e-45e7c0616171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['yolov7.pt'], source='vidd1.mp4', img_size=640, conf_thres=0.5, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "video 1/1 (1/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 3 dogs, Done. (1510.1ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (2/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 3 dogs, Done. (1403.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (3/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 3 dogs, Done. (1361.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (4/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sheep, Done. (1390.4ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (5/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sheep, Done. (1359.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (6/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sheep, Done. (1376.9ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (7/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sheep, Done. (2779.1ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (8/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sheep, Done. (2214.7ms) Inference, (2.6ms) NMS\n",
            "video 1/1 (9/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 3 persons, 2 dogs, 1 sheep, Done. (1428.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (10/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 3 dogs, 1 sheep, Done. (1358.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (11/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 3 dogs, 1 sheep, Done. (1362.6ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (12/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 3 dogs, 1 sheep, Done. (1350.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (13/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sheep, Done. (1357.4ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (14/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sheep, Done. (1367.6ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (15/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 2 dogs, 1 sheep, Done. (1343.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (16/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, 1 sheep, Done. (1907.4ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (17/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 sheep, Done. (2122.0ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (18/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 sheep, Done. (2004.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (19/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, 1 sheep, Done. (1370.1ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (20/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, 1 sheep, Done. (1352.8ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (21/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 2 sheeps, Done. (1364.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (22/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 2 sheeps, Done. (1375.5ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (23/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 sheep, Done. (1363.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (24/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 sheep, Done. (1344.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (25/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 sheep, Done. (1374.2ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (26/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 sheep, Done. (2130.0ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (27/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 sheep, Done. (2126.5ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (28/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1696.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (29/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 cow, Done. (1375.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (30/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1351.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (31/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1351.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (32/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1362.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (33/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, Done. (1345.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (34/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, Done. (1370.4ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (35/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1631.9ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (36/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, Done. (2117.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (37/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2186.7ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (38/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1365.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (39/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, Done. (1372.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (40/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, Done. (1351.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (41/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, Done. (1361.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (42/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1376.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (43/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1358.4ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (44/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1345.6ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (45/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1899.9ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (46/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, Done. (2117.4ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (47/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, Done. (1983.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (48/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 3 persons, Done. (1354.2ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (49/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, Done. (1346.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (50/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 1 dog, Done. (1365.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (51/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 2 dogs, Done. (1367.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (52/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 2 dogs, Done. (1350.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (53/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1349.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (54/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1401.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (55/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2113.0ms) Inference, (1.8ms) NMS\n",
            "video 1/1 (56/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (3039.6ms) Inference, (2.4ms) NMS\n",
            "video 1/1 (57/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (3734.3ms) Inference, (3.8ms) NMS\n",
            "video 1/1 (58/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2701.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (59/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1431.5ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (60/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 horses, Done. (1374.4ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (61/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 2 dogs, Done. (1372.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (62/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 2 dogs, Done. (2115.8ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (63/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 2 persons, 2 dogs, Done. (2119.8ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (64/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1792.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (65/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1365.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (66/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1378.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (67/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1376.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (68/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1356.7ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (69/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1366.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (70/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 cow, Done. (1365.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (71/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1625.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (72/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2108.5ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (73/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (2170.0ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (74/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1402.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (75/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1359.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (76/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1379.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (77/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1350.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (78/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1351.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (79/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1357.1ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (80/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1372.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (81/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1959.3ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (82/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2151.8ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (83/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1951.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (84/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1378.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (85/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1360.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (86/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1357.6ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (87/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1360.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (88/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1377.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (89/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1373.4ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (90/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1407.3ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (91/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2146.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (92/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2159.8ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (93/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1602.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (94/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1353.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (95/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1404.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (96/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1363.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (97/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 sports ball, Done. (1366.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (98/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 sports ball, Done. (1353.2ms) Inference, (1.8ms) NMS\n",
            "video 1/1 (99/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1359.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (100/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1812.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (101/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (2114.1ms) Inference, (1.8ms) NMS\n",
            "video 1/1 (102/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (2123.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (103/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1359.3ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (104/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1395.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (105/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1369.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (106/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1378.8ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (107/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 3 dogs, Done. (1372.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (108/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1364.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (109/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 cow, Done. (1371.7ms) Inference, (2.0ms) NMS\n",
            "video 1/1 (110/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, 1 cow, Done. (2115.3ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (111/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2144.8ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (112/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1724.3ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (113/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1368.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (114/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1378.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (115/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1374.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (116/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1358.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (117/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 2 cows, 1 sports ball, Done. (1360.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (118/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1355.4ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (119/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1663.7ms) Inference, (1.8ms) NMS\n",
            "video 1/1 (120/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2113.6ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (121/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (2184.8ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (122/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1350.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (123/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1374.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (124/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1361.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (125/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1375.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (126/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1357.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (127/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1369.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (128/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 sports ball, Done. (1388.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (129/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 3 dogs, Done. (1969.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (130/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2135.9ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (131/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1885.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (132/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1398.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (133/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 frisbee, Done. (1359.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (134/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, 1 frisbee, Done. (1361.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (135/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1367.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (136/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1360.4ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (137/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1348.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (138/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1497.3ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (139/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2102.5ms) Inference, (2.0ms) NMS\n",
            "video 1/1 (140/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2191.5ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (141/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1498.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (142/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1358.2ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (143/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1367.4ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (144/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1379.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (145/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1359.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (146/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1357.1ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (147/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1377.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (148/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1851.4ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (149/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2132.0ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (150/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2036.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (151/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1409.5ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (152/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1387.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (153/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1367.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (154/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1366.1ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (155/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1361.6ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (156/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1368.1ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (157/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1413.1ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (158/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2124.3ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (159/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (2163.8ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (160/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1643.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (161/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1354.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (162/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1374.6ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (163/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1383.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (164/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 2 dogs, Done. (1364.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (165/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1366.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (166/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1374.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (167/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1758.9ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (168/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2109.6ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (169/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2112.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (170/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1371.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (171/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1359.2ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (172/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1380.2ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (173/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1358.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (174/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1352.0ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (175/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1378.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (176/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1363.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (177/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2070.2ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (178/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2124.6ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (179/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1817.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (180/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1370.1ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (181/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1355.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (182/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1380.2ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (183/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1360.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (184/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1364.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (185/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1367.1ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (186/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1584.9ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (187/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2162.8ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (188/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (2157.0ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (189/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 person, 1 dog, Done. (1437.3ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (190/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 bench, 1 dog, Done. (1355.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (191/191) /content/drive/MyDrive/Mydir/yolov7/vidd1.mp4: 1 dog, Done. (1375.0ms) Inference, (1.3ms) NMS\n",
            "Done. (309.502s)\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights yolov7.pt --conf 0.5 --img-size 640 --source vidd1.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xnvPwIgIPxL"
      },
      "source": [
        "# **Custom object detection using Yolo v7 for images and videos**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdr5QVHwTk_7",
        "outputId": "d2110e8a-3f62-4fdf-e135-ea5011312def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mydir/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orNjlZs_8oSm",
        "outputId": "9f019435-5b61-41cb-d444-204c84424107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.4)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.12.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.13.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2HmUcepAgJl",
        "outputId": "c8ecb5d9-f499-447c-ac25-583cf9445b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.28)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msCdel2w84bq",
        "outputId": "1eb634cd-7c55-482f-b97d-4a23eb9b56a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mydir/yolov7\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr1lkTWsACwS",
        "outputId": "17143e96-7146-43fa-8261-0d9413129e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Trash-5 to yolov7pytorch:: 100%|██████████| 181410/181410 [00:22<00:00, 8120.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Trash-5 in yolov7pytorch:: 100%|██████████| 12260/12260 [02:13<00:00, 92.11it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YiwThvxIlO3S6XKvbxHC\")\n",
        "project = rf.workspace(\"nam-nhat\").project(\"trash-dvdrr\")\n",
        "version = project.version(5)\n",
        "dataset = version.download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_aT1UbrBCPi",
        "outputId": "2c2ed644-7be7-4609-ed5d-ec7fed5f790e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mydir/yolov7\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-3QvnpJRo4X",
        "outputId": "abe073c9-8adc-43bb-e39e-3bef0b0d269a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-09 03:26:59--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240509%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240509T032700Z&X-Amz-Expires=300&X-Amz-Signature=5a6bf15d21cefb10a1553ec6c756b5de39bdde99e0ce5fffb1d3adb2fb8fedf6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-09 03:27:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240509%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240509T032700Z&X-Amz-Expires=300&X-Amz-Signature=5a6bf15d21cefb10a1553ec6c756b5de39bdde99e0ce5fffb1d3adb2fb8fedf6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7.pt.3’\n",
            "\n",
            "yolov7.pt.3         100%[===================>]  72.08M  47.7MB/s    in 1.5s    \n",
            "\n",
            "2024-05-09 03:27:01 (47.7 MB/s) - ‘yolov7.pt.3’ saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz7hSAzYXaEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca294554-b51c-4d19-a3bc-bee32e3ab64f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-09 03:27:11.481452: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-09 03:27:12.516047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-09 03:27:15.141143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mydir/yolov7/train.py\", line 595, in <module>\n",
            "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
            "  File \"/content/drive/MyDrive/Mydir/yolov7/utils/torch_utils.py\", line 71, in select_device\n",
            "    assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability\n",
            "AssertionError: CUDA unavailable, invalid device 0 requested\n"
          ]
        }
      ],
      "source": [
        "!python train.py --batch 16 --cfg cfg/training/yolov7.yaml --epochs 55 --data {dataset.location}/data.yaml --weights 'yolov7.pt' --device 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekoupOxuXaOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4b0157-2314-411e-d804-d85c7a31c91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['/content/drive/MyDrive/yolov7/runs/train/exp/weights/epoch_000.pt'], source='/content/gdrive/MyDrive/yolov7/Trash-5/test/images', img_size=640, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mydir/yolov7/detect.py\", line 196, in <module>\n",
            "    detect()\n",
            "  File \"/content/drive/MyDrive/Mydir/yolov7/detect.py\", line 34, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "  File \"/content/drive/MyDrive/Mydir/yolov7/models/experimental.py\", line 252, in attempt_load\n",
            "    ckpt = torch.load(w, map_location=map_location)  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 998, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 445, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 426, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/yolov7/runs/train/exp/weights/epoch_000.pt'\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "!python detect.py --weights /content/drive/MyDrive/yolov7/runs/train/exp/weights/epoch_000.pt --conf 0.1 --source /content/gdrive/MyDrive/yolov7/Trash-5/test/images"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}